(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG$ cd project/
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ ls
data_generator.py    deep_learning_anomaly_detector.py  main.py              models  README.md         results
data_preparation.py  feature_engineering.py             model_evaluation.py  plots   requirements.txt  statistical_anomaly_detector.py
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ python data_generator.py
Generating 10000 samples with 5 sensors...
Data saved to sensor_data.csv
Total anomalies injected: 500 (5.0%)

Dataset shape: (10000, 7)

First few rows:
            timestamp   sensor_0   sensor_1   sensor_2   sensor_3   sensor_4  is_anomaly
0 2024-01-01 00:00:00  20.248357  24.660753  30.174143  34.009714  39.764071           0
1 2024-01-01 01:00:00  20.782607  25.698990  30.993401  35.324247  41.358091           0
2 2024-01-01 02:00:00  21.974305  26.351770  31.182200  36.356946  41.551367           0
3 2024-01-01 03:00:00  23.108264  27.401958  32.636542  37.421584  42.392034           0
4 2024-01-01 04:00:00  22.781084  28.496750  32.153120  38.410242  43.256856           0
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ python data_preparation.py

============================================================
EXPLORATORY DATA ANALYSIS
============================================================
Loading data...
Data loaded: (10000, 7)

Checking for missing values...
Series([], dtype: int64)
No missing values found

============================================================
BASIC STATISTICS
============================================================
           sensor_0      sensor_1      sensor_2      sensor_3      sensor_4
count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000
mean      23.258257     28.166441     33.151700     37.961522     43.074476
std        4.088838      4.149801      4.183245      3.973060      4.150718
min       -0.667180      3.574541      9.371152     14.745093     17.141038
25%       20.639786     25.489505     30.503692     35.494812     40.530306
50%       23.016392     27.881954     32.871163     37.779620     42.801841
75%       25.457982     30.359714     35.281490     40.118837     45.184266
max       47.538038     53.102615     59.938596     65.480211     73.717311

Detecting outliers (Z-score > 3)...
Outlier counts per sensor:
  sensor_0: 150 outliers (1.50%)
  sensor_1: 158 outliers (1.58%)
  sensor_2: 177 outliers (1.77%)
  sensor_3: 196 outliers (1.96%)
  sensor_4: 190 outliers (1.90%)

Time series plot saved to plots/time_series.png
Distribution plot saved to plots/distributions.png
Correlation matrix saved to plots/correlation_matrix.png
Boxplots saved to plots/boxplots.png

============================================================
EDA COMPLETE - All plots saved to 'plots/' directory
============================================================
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ python feature_engineering.py

============================================================
FEATURE ENGINEERING
============================================================
Starting shape: (10000, 7)

Creating rolling features with windows: [5, 10, 20]
Created rolling features. New shape: (10000, 67)

Creating lag features with lags: [1, 2, 3, 5, 10]
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:67: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  self.df.fillna(method='bfill', inplace=True)
Created lag features. New shape: (10000, 92)

Creating difference features...
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:83: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  self.df.fillna(method='bfill', inplace=True)
Created difference features. New shape: (10000, 102)

Creating rate of change features with periods: [5, 10]
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  self.df[f'{sensor}_roc_{period}'] = (
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:104: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  self.df.fillna(method='bfill', inplace=True)
Created rate of change features. New shape: (10000, 112)

Creating statistical features with window: 20
/home/vaalisaran/Codings/Projects/OG/project/feature_engineering.py:129: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  self.df.fillna(method='bfill', inplace=True)
Created statistical features. New shape: (10000, 122)

Creating cross-sensor features...
Created cross-sensor features. New shape: (10000, 144)

Creating time-based features...
Created time-based features. New shape: (10000, 151)

Normalizing features using robust scaler...
Features normalized. Total features: 149
Scaler saved to models/scaler.pkl

============================================================
FEATURE ENGINEERING COMPLETE
Final shape: (10000, 151)
Total features created: 149
============================================================

Featured data saved to 'sensor_data_features.csv'
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ python statistical_anomaly_detector.py

============================================================
STATISTICAL ANOMALY DETECTION
============================================================

============================================================
ISOLATION FOREST
============================================================
Training with 100 estimators...
Expected contamination: 5.0%
Detected 500 anomalies (5.00%)
============================================================

============================================================
LOCAL OUTLIER FACTOR
============================================================
Using 20 neighbors...
Expected contamination: 5.0%
Detected 500 anomalies (5.00%)
============================================================

============================================================
ELLIPTIC ENVELOPE
============================================================
Expected contamination: 5.0%
Detected 500 anomalies (5.00%)
============================================================

============================================================
Z-SCORE METHOD
============================================================
Using threshold: 3 standard deviations
Detected 3777 anomalies (37.77%)
============================================================

============================================================
ENSEMBLE PREDICTION
============================================================
Using 4 models
Minimum votes required: 2
Detected 1024 anomalies (10.24%)
============================================================

Models saved to models/statistical_models.pkl

Results saved to 'results_statistical.csv'
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ python deep_learning_anomaly_detector.py
2025-11-06 15:17:50.758537: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.
2025-11-06 15:17:50.831845: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-11-06 15:17:52.912018: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.

Training Autoencoder...

============================================================
BUILDING AUTOENCODER
============================================================
Input dimension: 149
Encoding dimension: 32
Hidden layers: [128, 64, 32]
2025-11-06 15:17:54.426135: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
Total parameters: 63,093
============================================================
Epoch 1/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 5s 16ms/step - loss: 2.8518 - mae: 1.0069 - val_loss: 1.9421 - val_mae: 0.7511 - learning_rate: 0.0010
Epoch 2/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 2.1241 - mae: 0.8295 - val_loss: 1.5147 - val_mae: 0.6847 - learning_rate: 0.0010
Epoch 3/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - loss: 1.7641 - mae: 0.7523 - val_loss: 1.2753 - val_mae: 0.6287 - learning_rate: 0.0010
Epoch 4/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.5462 - mae: 0.7111 - val_loss: 1.1339 - val_mae: 0.5906 - learning_rate: 0.0010
Epoch 5/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.4682 - mae: 0.6887 - val_loss: 1.0703 - val_mae: 0.5676 - learning_rate: 0.0010
Epoch 6/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.3980 - mae: 0.6713 - val_loss: 1.0379 - val_mae: 0.5580 - learning_rate: 0.0010
Epoch 7/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.3565 - mae: 0.6583 - val_loss: 1.0001 - val_mae: 0.5441 - learning_rate: 0.0010
Epoch 8/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.3222 - mae: 0.6475 - val_loss: 0.9848 - val_mae: 0.5351 - learning_rate: 0.0010
Epoch 9/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.3000 - mae: 0.6400 - val_loss: 0.9632 - val_mae: 0.5286 - learning_rate: 0.0010
Epoch 10/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.2716 - mae: 0.6327 - val_loss: 0.9507 - val_mae: 0.5232 - learning_rate: 0.0010
Epoch 11/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.2585 - mae: 0.6260 - val_loss: 0.9357 - val_mae: 0.5204 - learning_rate: 0.0010
Epoch 12/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.2369 - mae: 0.6251 - val_loss: 0.9158 - val_mae: 0.5152 - learning_rate: 0.0010
Epoch 13/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.2218 - mae: 0.6179 - val_loss: 0.9096 - val_mae: 0.5113 - learning_rate: 0.0010
Epoch 14/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1947 - mae: 0.6118 - val_loss: 0.8957 - val_mae: 0.5089 - learning_rate: 0.0010
Epoch 15/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1973 - mae: 0.6110 - val_loss: 0.8869 - val_mae: 0.5043 - learning_rate: 0.0010
Epoch 16/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1737 - mae: 0.6076 - val_loss: 0.8807 - val_mae: 0.5018 - learning_rate: 0.0010
Epoch 17/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1674 - mae: 0.6054 - val_loss: 0.8785 - val_mae: 0.5014 - learning_rate: 0.0010
Epoch 18/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1707 - mae: 0.6027 - val_loss: 0.8695 - val_mae: 0.4993 - learning_rate: 0.0010
Epoch 19/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1470 - mae: 0.6001 - val_loss: 0.8535 - val_mae: 0.4938 - learning_rate: 0.0010
Epoch 20/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1387 - mae: 0.5967 - val_loss: 0.8473 - val_mae: 0.4907 - learning_rate: 0.0010
Epoch 21/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1396 - mae: 0.5968 - val_loss: 0.8365 - val_mae: 0.4863 - learning_rate: 0.0010
Epoch 22/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1286 - mae: 0.5943 - val_loss: 0.8321 - val_mae: 0.4856 - learning_rate: 0.0010
Epoch 23/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1196 - mae: 0.5912 - val_loss: 0.8264 - val_mae: 0.4814 - learning_rate: 0.0010
Epoch 24/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1104 - mae: 0.5876 - val_loss: 0.8201 - val_mae: 0.4787 - learning_rate: 0.0010
Epoch 25/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1127 - mae: 0.5878 - val_loss: 0.8137 - val_mae: 0.4749 - learning_rate: 0.0010
Epoch 26/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.1023 - mae: 0.5827 - val_loss: 0.8025 - val_mae: 0.4675 - learning_rate: 0.0010
Epoch 27/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0904 - mae: 0.5812 - val_loss: 0.7929 - val_mae: 0.4609 - learning_rate: 0.0010
Epoch 28/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0920 - mae: 0.5770 - val_loss: 0.7896 - val_mae: 0.4589 - learning_rate: 0.0010
Epoch 29/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0793 - mae: 0.5736 - val_loss: 0.7829 - val_mae: 0.4551 - learning_rate: 0.0010
Epoch 30/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0869 - mae: 0.5742 - val_loss: 0.7837 - val_mae: 0.4547 - learning_rate: 0.0010
Epoch 31/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0623 - mae: 0.5685 - val_loss: 0.7862 - val_mae: 0.4509 - learning_rate: 0.0010
Epoch 32/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0690 - mae: 0.5683 - val_loss: 0.7735 - val_mae: 0.4490 - learning_rate: 0.0010
Epoch 33/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0733 - mae: 0.5685 - val_loss: 0.7660 - val_mae: 0.4455 - learning_rate: 0.0010
Epoch 34/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - loss: 1.0522 - mae: 0.5647 - val_loss: 0.7678 - val_mae: 0.4443 - learning_rate: 0.0010
Epoch 35/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0572 - mae: 0.5657 - val_loss: 0.7580 - val_mae: 0.4421 - learning_rate: 0.0010
Epoch 36/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0512 - mae: 0.5634 - val_loss: 0.7605 - val_mae: 0.4425 - learning_rate: 0.0010
Epoch 37/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0462 - mae: 0.5634 - val_loss: 0.7557 - val_mae: 0.4418 - learning_rate: 0.0010
Epoch 38/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0297 - mae: 0.5589 - val_loss: 0.7484 - val_mae: 0.4358 - learning_rate: 0.0010
Epoch 39/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0359 - mae: 0.5590 - val_loss: 0.7459 - val_mae: 0.4367 - learning_rate: 0.0010
Epoch 40/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0408 - mae: 0.5603 - val_loss: 0.7432 - val_mae: 0.4358 - learning_rate: 0.0010
Epoch 41/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0372 - mae: 0.5584 - val_loss: 0.7350 - val_mae: 0.4336 - learning_rate: 0.0010
Epoch 42/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0364 - mae: 0.5605 - val_loss: 0.7301 - val_mae: 0.4335 - learning_rate: 0.0010
Epoch 43/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0237 - mae: 0.5572 - val_loss: 0.7326 - val_mae: 0.4329 - learning_rate: 0.0010
Epoch 44/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0281 - mae: 0.5566 - val_loss: 0.7281 - val_mae: 0.4332 - learning_rate: 0.0010
Epoch 45/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0237 - mae: 0.5562 - val_loss: 0.7259 - val_mae: 0.4299 - learning_rate: 0.0010
Epoch 46/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0143 - mae: 0.5542 - val_loss: 0.7239 - val_mae: 0.4290 - learning_rate: 0.0010
Epoch 47/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0120 - mae: 0.5533 - val_loss: 0.7222 - val_mae: 0.4282 - learning_rate: 0.0010
Epoch 48/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0138 - mae: 0.5542 - val_loss: 0.7200 - val_mae: 0.4292 - learning_rate: 0.0010
Epoch 49/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - loss: 1.0208 - mae: 0.5532 - val_loss: 0.7172 - val_mae: 0.4284 - learning_rate: 0.0010
Epoch 50/50
63/63 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - loss: 1.0142 - mae: 0.5529 - val_loss: 0.7136 - val_mae: 0.4244 - learning_rate: 0.0010

============================================================
AUTOENCODER PREDICTION
============================================================
Threshold (MSE): 2.461669
Detected 500 anomalies (5.00%)
============================================================

Training LSTM Autoencoder...
Training sequences shape: (7991, 10, 149)
Validation sequences shape: (1991, 10, 149)

============================================================
BUILDING LSTM AUTOENCODER
============================================================
Timesteps: 10
Features per timestep: 149
Encoding dimension: 32
Total parameters: 355,349
============================================================
2025-11-06 15:18:30.391588: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 47626360 exceeds 10% of free system memory.
2025-11-06 15:18:30.633407: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 47626360 exceeds 10% of free system memory.
Epoch 1/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 20s 92ms/step - loss: 2.3516 - mae: 0.8134 - val_loss: 2.0876 - val_mae: 0.7891 - learning_rate: 0.0010
Epoch 2/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 63ms/step - loss: 2.2580 - mae: 0.8216 - val_loss: 2.0255 - val_mae: 0.7900 - learning_rate: 0.0010
Epoch 3/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 63ms/step - loss: 2.1968 - mae: 0.8191 - val_loss: 1.9732 - val_mae: 0.7897 - learning_rate: 0.0010
Epoch 4/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 65ms/step - loss: 2.1228 - mae: 0.8125 - val_loss: 1.9179 - val_mae: 0.7806 - learning_rate: 0.0010
Epoch 5/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 69ms/step - loss: 2.0424 - mae: 0.8037 - val_loss: 1.8587 - val_mae: 0.7753 - learning_rate: 0.0010
Epoch 6/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 68ms/step - loss: 1.9696 - mae: 0.7937 - val_loss: 1.8047 - val_mae: 0.7644 - learning_rate: 0.0010
Epoch 7/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 68ms/step - loss: 1.8988 - mae: 0.7842 - val_loss: 1.8021 - val_mae: 0.7616 - learning_rate: 0.0010
Epoch 8/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 67ms/step - loss: 1.8665 - mae: 0.7796 - val_loss: 1.7936 - val_mae: 0.7605 - learning_rate: 0.0010
Epoch 9/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 66ms/step - loss: 1.8240 - mae: 0.7732 - val_loss: 1.7699 - val_mae: 0.7571 - learning_rate: 0.0010
Epoch 10/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 67ms/step - loss: 1.8070 - mae: 0.7708 - val_loss: 1.7524 - val_mae: 0.7538 - learning_rate: 0.0010
Epoch 11/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 68ms/step - loss: 1.7887 - mae: 0.7679 - val_loss: 1.7514 - val_mae: 0.7551 - learning_rate: 0.0010
Epoch 12/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 69ms/step - loss: 1.7629 - mae: 0.7641 - val_loss: 1.7307 - val_mae: 0.7507 - learning_rate: 0.0010
Epoch 13/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 68ms/step - loss: 1.7512 - mae: 0.7622 - val_loss: 1.7300 - val_mae: 0.7496 - learning_rate: 0.0010
Epoch 14/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 68ms/step - loss: 1.7369 - mae: 0.7602 - val_loss: 1.7187 - val_mae: 0.7512 - learning_rate: 0.0010
Epoch 15/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 68ms/step - loss: 1.7187 - mae: 0.7576 - val_loss: 1.7071 - val_mae: 0.7484 - learning_rate: 0.0010
Epoch 16/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 10s 83ms/step - loss: 1.7091 - mae: 0.7562 - val_loss: 1.7156 - val_mae: 0.7499 - learning_rate: 0.0010
Epoch 17/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 11s 86ms/step - loss: 1.6931 - mae: 0.7540 - val_loss: 1.7021 - val_mae: 0.7459 - learning_rate: 0.0010
Epoch 18/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 66ms/step - loss: 1.6887 - mae: 0.7533 - val_loss: 1.7085 - val_mae: 0.7489 - learning_rate: 0.0010
Epoch 19/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 68ms/step - loss: 1.6748 - mae: 0.7515 - val_loss: 1.6857 - val_mae: 0.7458 - learning_rate: 0.0010
Epoch 20/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 68ms/step - loss: 1.6682 - mae: 0.7505 - val_loss: 1.6919 - val_mae: 0.7466 - learning_rate: 0.0010
Epoch 21/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 67ms/step - loss: 1.6562 - mae: 0.7491 - val_loss: 1.6912 - val_mae: 0.7470 - learning_rate: 0.0010
Epoch 22/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 9s 68ms/step - loss: 1.6489 - mae: 0.7483 - val_loss: 1.6748 - val_mae: 0.7454 - learning_rate: 0.0010
Epoch 23/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 66ms/step - loss: 1.6450 - mae: 0.7476 - val_loss: 1.6813 - val_mae: 0.7483 - learning_rate: 0.0010
Epoch 24/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 67ms/step - loss: 1.6268 - mae: 0.7450 - val_loss: 1.6764 - val_mae: 0.7456 - learning_rate: 0.0010
Epoch 25/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 10s 64ms/step - loss: 1.6212 - mae: 0.7444 - val_loss: 1.6717 - val_mae: 0.7461 - learning_rate: 0.0010
Epoch 26/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 65ms/step - loss: 1.6171 - mae: 0.7440 - val_loss: 1.6787 - val_mae: 0.7464 - learning_rate: 0.0010
Epoch 27/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 67ms/step - loss: 1.6131 - mae: 0.7434 - val_loss: 1.6641 - val_mae: 0.7437 - learning_rate: 0.0010
Epoch 28/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 67ms/step - loss: 1.5992 - mae: 0.7414 - val_loss: 1.6637 - val_mae: 0.7425 - learning_rate: 0.0010
Epoch 29/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 67ms/step - loss: 1.5915 - mae: 0.7399 - val_loss: 1.6573 - val_mae: 0.7441 - learning_rate: 0.0010
Epoch 30/30
125/125 ━━━━━━━━━━━━━━━━━━━━ 8s 66ms/step - loss: 1.5864 - mae: 0.7392 - val_loss: 1.6683 - val_mae: 0.7425 - learning_rate: 0.0010

============================================================
LSTM AUTOENCODER PREDICTION
============================================================
2025-11-06 15:22:59.280437: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 59546360 exceeds 10% of free system memory.
2025-11-06 15:23:04.689092: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 59546360 exceeds 10% of free system memory.
Threshold (MSE): 5.936056
Detected 500 anomalies (5.00%)
============================================================
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
Autoencoder saved to models/autoencoder.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
LSTM Autoencoder saved to models/lstm_autoencoder.h5
Thresholds saved to models/thresholds.pkl

Results saved to 'results_deep_learning.csv'
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ python model_evaluation.py

================================================================================
RUNNING FULL EVALUATION
================================================================================

================================================================================
MODEL EVALUATION
================================================================================

PERFORMANCE METRICS:
--------------------------------------------------------------------------------
Method                    Precision    Recall       F1-Score     Detected    
--------------------------------------------------------------------------------
ensemble                  0.3408       0.6980       0.4580       1024        
isolation_forest          0.4200       0.4200       0.4200       500         
lof                       0.3240       0.3240       0.3240       500         
autoencoder               0.3080       0.3080       0.3080       500         
elliptic_envelope         0.3020       0.3020       0.3020       500         
z_score                   0.1115       0.8420       0.1969       3777        
lstm_autoencoder          0.0620       0.0620       0.0620       500         
--------------------------------------------------------------------------------
Total actual anomalies: 500
================================================================================

Confusion matrices saved to plots/confusion_matrices.png
ROC curves saved to plots/roc_curves.png
Precision-Recall curves saved to plots/pr_curves.png
Anomaly timeline saved to plots/anomaly_timeline.png

Comparison report saved to evaluation_report.txt

================================================================================
EVALUATION COMPLETE
================================================================================

Top 3 Methods by F1-Score:
             method  precision  recall  f1_score
4          ensemble    0.34082   0.698  0.458005
0  isolation_forest    0.42000   0.420  0.420000
1               lof    0.32400   0.324  0.324000
(myenv) vaalisaran@vaali-saran-pc:~/Codings/Projects/OG/project$ 


